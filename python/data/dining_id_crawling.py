from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.chrome.service import Service
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import StaleElementReferenceException, TimeoutException
from webdriver_manager.chrome import ChromeDriverManager
import pandas as pd
import time
import urllib.parse

# ë‹¤ì´ë‹ì½”ë“œ ê¸°ë³¸ URL
BASE_URL = "https://www.diningcode.com/"

# ì£¼ì†Œì—ì„œ "êµ¬" ë˜ëŠ” "ë¡œ"ê¹Œì§€ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
def extract_location(address):
    idx = address.find("êµ¬")
    if idx != -1:
        return address[:idx+1]
    idx = address.find("ë¡œ")
    if idx != -1:
        return address[:idx+1]
    return address

# a íƒœê·¸ì˜ hrefë¥¼ ì¬ì‹œë„í•˜ì—¬ ì¶”ì¶œí•˜ëŠ” í•¨ìˆ˜
def get_href_retry(driver, retries=3, delay=1):
    for attempt in range(retries):
        try:
            # êµ¬ì²´ì ì¸ ì„ íƒì ì‚¬ìš©: Poi__List__Wrap ì˜ì—­ ë‚´ì˜ a.PoiBlock
            a_tag = WebDriverWait(driver, 10).until(
                EC.element_to_be_clickable((By.CSS_SELECTOR, "div.Poi__List__Wrap a.PoiBlock"))
            )
            href = a_tag.get_attribute("href")
            if href:
                return href
        except (StaleElementReferenceException, TimeoutException):
            time.sleep(delay)
    return None

# í¬ë¡¬ ë“œë¼ì´ë²„ ì˜µì…˜ ì„¤ì •
options = webdriver.ChromeOptions()
# options.add_argument("--headless")  # ê²°ê³¼ë¥¼ ëˆˆìœ¼ë¡œ í™•ì¸í•˜ë ¤ë©´ headless ëª¨ë“œ í•´ì œ
options.add_argument("--no-sandbox")
options.add_argument("--disable-dev-shm-usage")

driver = webdriver.Chrome(service=Service(ChromeDriverManager().install()), options=options)

# CSVì—ì„œ ê°€ê²Œëª…ê³¼ ì£¼ì†Œ ì½ê¸°
input_csv = "okay_zone_restlist.csv"
try:
    df = pd.read_csv(input_csv, encoding="cp949")
    df = df.dropna(subset=["cot_conts_name", "cot_addr_full_new"])
    # ê° í–‰ì—ì„œ (ê°€ê²Œëª…, "ê°€ê²Œëª… + ì¶”ì¶œëœ ì£¼ì†Œ") íŠœí”Œ ìƒì„±
    search_queries = df.apply(
        lambda row: (row['cot_conts_name'], f"{row['cot_conts_name']} {extract_location(row['cot_addr_full_new'])}"),
        axis=1
    ).tolist()
except FileNotFoundError:
    print(f"âŒ íŒŒì¼ `{input_csv}`ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
    driver.quit()
    exit()

results = []

for idx, (restaurant_name, search_query) in enumerate(search_queries):
    print(f"ğŸ” `{search_query}` ê²€ìƒ‰ ì¤‘... ({idx+1}/{len(search_queries)})")
    try:
        # ê²€ìƒ‰ì–´ URL ì¸ì½”ë”© ë° ê²€ìƒ‰ URL ìƒì„±
        encoded_query = urllib.parse.quote(search_query)
        search_url = BASE_URL + "list.dc?query=" + encoded_query
        driver.get(search_url)
        # ê²€ìƒ‰ ê²°ê³¼ ë¦¬ìŠ¤íŠ¸ ì˜ì—­ì´ ë¡œë“œë  ë•Œê¹Œì§€ ëŒ€ê¸°
        WebDriverWait(driver, 10).until(
            EC.presence_of_element_located((By.CSS_SELECTOR, "div.Poi__List__Wrap"))
        )
        time.sleep(1)  # ì»¨í…Œì´ë„ˆ ì•ˆì •í™”ë¥¼ ìœ„í•œ ì ê¹ ëŒ€ê¸°

        # ì§€ì •í•œ ì˜ì—­ ë‚´ì˜ a íƒœê·¸ì˜ href ì†ì„±ì„ ì¬ì‹œë„í•˜ì—¬ ì¶”ì¶œ
        href = get_href_retry(driver, retries=3, delay=1)
        print(f"DEBUG: {restaurant_name} href: {href}")
        if not href:
            print(f"âŒ {restaurant_name}ì˜ href ì†ì„±ì„ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
            continue

        # href ë¬¸ìì—´ì—ì„œ "rid=" ì´í›„ í…ìŠ¤íŠ¸ ì¶”ì¶œ
        if "rid=" in href:
            restaurant_id = href.split("rid=")[1].split("&")[0]
        else:
            restaurant_id = "ID ì¶”ì¶œ ì‹¤íŒ¨"
        print(f"âœ… {restaurant_name} - ID: {restaurant_id}")
        results.append({
            "ê°€ê²Œëª…": restaurant_name,
            "ê°€ê²ŒID": restaurant_id
        })
    except Exception as e:
        print(f"âŒ `{search_query}` í¬ë¡¤ë§ ì˜¤ë¥˜: {e}")

driver.quit()
output_csv = "restaurant_list_dining.csv"
pd.DataFrame(results).to_csv(output_csv, index=False, encoding="utf-8-sig")
print(f"âœ… ë°ì´í„° ì €ì¥ ì™„ë£Œ! íŒŒì¼: {output_csv}")
