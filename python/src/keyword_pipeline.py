import json
import os
from src.hadoop.hdfs_client import HDFSClient
from src.keyword.analysis import KeywordAnalyzer
from dotenv import load_dotenv
from db.database import \
  PostgresImporter  # database.pyì—ì„œ PostgresImporter í´ë˜ìŠ¤ ì„í¬íŠ¸

# .env íŒŒì¼ ë¡œë“œ
load_dotenv()


def main(restaurant_ids=None):
  """
  HDFSì—ì„œ JSON íŒŒì¼ì„ ì½ì–´ í‚¤ì›Œë“œ ë¶„ì„ì„ ì‹¤í–‰í•˜ê³  ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•˜ëŠ” ë©”ì¸ í•¨ìˆ˜

  Args:
      restaurant_ids (list, range, optional): ì²˜ë¦¬í•  ë ˆìŠ¤í† ë‘ ID ëª©ë¡. ê¸°ë³¸ê°’ì€ None (ì´ ê²½ìš° ID 1ë§Œ ì²˜ë¦¬)
  """
  # HDFS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™”
  try:
    hdfs_client = HDFSClient()
    print("âœ… HDFS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
  except ValueError as e:
    print(f"âŒ HDFS í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì‹¤íŒ¨: {e}")
    return

  # í‚¤ì›Œë“œ ë¶„ì„ê¸° ì´ˆê¸°í™”
  analyzer = KeywordAnalyzer()
  print("âœ… í‚¤ì›Œë“œ ë¶„ì„ê¸° ì´ˆê¸°í™” ì„±ê³µ")

  # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì´ˆê¸°í™”
  try:
    db_importer = PostgresImporter()
    print("âœ… ë°ì´í„°ë² ì´ìŠ¤ í´ë¼ì´ì–¸íŠ¸ ì´ˆê¸°í™” ì„±ê³µ")
  except Exception as e:
    print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì‹¤íŒ¨: {e}")
    return

  # restaurant_idsê°€ ìˆ«ì í•˜ë‚˜ì¸ ê²½ìš°(ì •ìˆ˜) ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
  if isinstance(restaurant_ids, int):
    restaurant_ids = [restaurant_ids]

  # ê° ë ˆìŠ¤í† ë‘ IDì— ëŒ€í•´ ì²˜ë¦¬ ì‹¤í–‰
  for restaurant_id in restaurant_ids:
    # IDë¥¼ ë¬¸ìì—´ë¡œ ë³€í™˜
    restaurant_id_str = str(restaurant_id)
    print(f"\n{'=' * 50}")
    print(f"ğŸ½ï¸ ë ˆìŠ¤í† ë‘ ID: {restaurant_id_str} ì²˜ë¦¬ ì‹œì‘")
    print(f"{'=' * 50}")

    # HDFS ë””ë ‰í† ë¦¬ ê²½ë¡œ ì„¤ì • (ë ˆìŠ¤í† ë‘ ë¦¬ë·°ì™€ ë¸”ë¡œê·¸ ë¦¬ë·°)
    hdfs_directories = [
      f"/user/hadoop/big_final_rest_review_json2/restaurant_id={restaurant_id_str}",
      f"/user/hadoop/big_final_rest_ugc_review_json2/restaurant_id={restaurant_id_str}"
    ]

    all_processed_reviews = []

    # ë””ë ‰í† ë¦¬ë³„ ì²˜ë¦¬
    for hdfs_directory in hdfs_directories:
      # ë¦¬ë·° ì†ŒìŠ¤ íƒ€ì… ì‹ë³„ (ë¸”ë¡œê·¸ ë¦¬ë·° ë˜ëŠ” ì¼ë°˜ ë¦¬ë·°)
      is_blog_review = "ugc_review" in hdfs_directory
      review_source = "ë¸”ë¡œê·¸" if is_blog_review else "í”Œë ˆì´ìŠ¤"
      print(f"ğŸ“‚ {review_source} ë¦¬ë·° ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ì‹œì‘: {hdfs_directory}")

      # ë””ë ‰í† ë¦¬ë³„ ì²˜ë¦¬ëœ ë¦¬ë·° ì¹´ìš´íŠ¸ ë³€ìˆ˜ ì´ˆê¸°í™”
      directory_processed_reviews = []

      try:
        # ëª¨ë“  JSON íŒŒì¼ ì¬ê·€ì ìœ¼ë¡œ ê°€ì ¸ì˜¤ê¸°
        json_files = hdfs_client.get_all_json_files(hdfs_directory)

        if not json_files:
          print(f"âŒ ë””ë ‰í† ë¦¬ '{hdfs_directory}'ì— JSON íŒŒì¼ì´ ì—†ìŠµë‹ˆë‹¤.")
          continue

        # ê° JSON íŒŒì¼ ì²˜ë¦¬
        for file_path in json_files:
          print(f"ğŸ” íŒŒì¼ ì²˜ë¦¬ ì¤‘: {file_path}")

          try:
            # HDFSì—ì„œ JSON íŒŒì¼ ì½ê¸°
            json_content = hdfs_client.read_file(file_path)

            # JSON íŒŒì‹± (ë¼ì¸ ë‹¨ìœ„ ë˜ëŠ” ì „ì²´ JSON ê°ì²´)
            try:
              # ì „ì²´ JSON ê°ì²´ í˜•ì‹ ì²˜ë¦¬ ì‹œë„
              data = json.loads(json_content)

              # processed_review í•„ë“œì—ì„œ ë¦¬ë·° í…ìŠ¤íŠ¸ ì¶”ì¶œ
              if "processed_review" in data:
                reviews = analyzer.extract_reviews(data["processed_review"])
                print(f"ğŸ“Š ì´ {len(reviews)}ê°œì˜ ë¦¬ë·°ë¥¼ ì¶”ì¶œí–ˆìŠµë‹ˆë‹¤.")
              else:
                # review_total_text í•„ë“œê°€ ì—†ëŠ” ê²½ìš° ì¼ë°˜ JSON ì²˜ë¦¬
                reviews = []
                if isinstance(data, list):
                  reviews = data
                elif isinstance(data, dict) and 'reviews' in data:
                  reviews = data['reviews']
                else:
                  reviews = [data]  # ë‹¨ì¼ ë¦¬ë·°ì¸ ê²½ìš°

            except json.JSONDecodeError:
              # JSON íŒŒì‹± ì‹¤íŒ¨ì‹œ ë¼ì¸ ë‹¨ìœ„ ì²˜ë¦¬ ì‹œë„
              print("âš ï¸ JSON íŒŒì‹± ì‹¤íŒ¨, ë¼ì¸ ë‹¨ìœ„ë¡œ ì²˜ë¦¬ë¥¼ ì‹œë„í•©ë‹ˆë‹¤.")
              reviews = []
              for line in json_content.strip().split('\n'):
                if line.strip():
                  try:
                    review = json.loads(line)
                    reviews.append(review)
                  except json.JSONDecodeError:
                    continue

            print(f"ğŸ“Š ì´ {len(reviews)}ê°œì˜ ë¦¬ë·°ë¥¼ íŒŒì‹±í–ˆìŠµë‹ˆë‹¤.")

            # ë¦¬ë·°ì— 'content' í•„ë“œê°€ ì—†ëŠ” ê²½ìš° ì²˜ë¦¬
            valid_reviews = []
            for review in reviews:
              if isinstance(review, dict):
                # 'content' í•„ë“œê°€ ì—†ìœ¼ë©´ 'text' ë˜ëŠ” 'review_text' í•„ë“œ ì°¾ê¸°
                if 'content' not in review:
                  for field in ['text', 'review_text', 'review', 'comment']:
                    if field in review:
                      review['content'] = review[field]
                      break

                # ì—¬ì „íˆ 'content' í•„ë“œê°€ ì—†ìœ¼ë©´ ê±´ë„ˆë›°ê¸°
                if 'content' in review:
                  # ë¦¬ë·° ì†ŒìŠ¤ ì •ë³´ ì¶”ê°€
                  review['source'] = review_source
                  valid_reviews.append(review)

            # í‚¤ì›Œë“œ ë¶„ì„ ì‹¤í–‰
            processed_reviews = analyzer.process_reviews(valid_reviews)
            directory_processed_reviews.extend(processed_reviews)
            all_processed_reviews.extend(processed_reviews)

          except Exception as e:
            print(f"âŒ íŒŒì¼ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
            continue

        # ë””ë ‰í† ë¦¬ë³„ ì²˜ë¦¬ëœ ë¦¬ë·° ìˆ˜ ì¶œë ¥
        review_count = len(directory_processed_reviews)
        print(
            f"ğŸ“Š ë””ë ‰í† ë¦¬ '{hdfs_directory}'ì—ì„œ ì²˜ë¦¬ëœ {review_source} ë¦¬ë·° ìˆ˜: {review_count}")

        if is_blog_review:
          blog_review_count = review_count
          print(f"ğŸ“ ë¸”ë¡œê·¸ ë¦¬ë·° ì²˜ë¦¬ ìˆ˜: {blog_review_count}")
        else:
          normal_review_count = review_count
          print(f"ğŸ“ ë„¤ì´ë²„ ë¦¬ë·° ì²˜ë¦¬ ìˆ˜: {normal_review_count}")

      except Exception as e:
        print(f"âŒ ë””ë ‰í† ë¦¬ ì²˜ë¦¬ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")

    if all_processed_reviews:
      # ëª¨ë“  ì²˜ë¦¬ëœ ë¦¬ë·°ì— ëŒ€í•œ ë¶„ì„ ì‹¤í–‰
      print(f"ğŸ“Š ì´ {len(all_processed_reviews)}ê°œì˜ ë¦¬ë·°ë¥¼ ë¶„ì„í•©ë‹ˆë‹¤...")

      # ì†ŒìŠ¤ë³„ ë¦¬ë·° ìˆ˜ ì¶œë ¥
      blog_reviews = [r for r in all_processed_reviews if
                      r.get('source') == 'ë¸”ë¡œê·¸']
      normal_reviews = [r for r in all_processed_reviews if
                        r.get('source') == 'í”Œë ˆì´ìŠ¤']
      print(f"ğŸ“Š ë„¤ì´ë²„ ë¦¬ë·° ìˆ˜: {len(normal_reviews)}")
      print(f"ğŸ“Š ë¸”ë¡œê·¸ ë¦¬ë·° ìˆ˜: {len(blog_reviews)}")

      # ìƒìœ„ 5ê°œ í‚¤ì›Œë“œë§Œ ë¶„ì„í•˜ë„ë¡ ì„¤ì •
      top_n = 5
      reviews_per_keyword = 20  # ê° í‚¤ì›Œë“œë‹¹ ìµœëŒ€ 20ê°œ ë¦¬ë·°

      analysis_results = analyzer.analyze_reviews(
          all_processed_reviews,
          top_n=top_n,
          reviews_per_keyword=reviews_per_keyword
      )

      # ë³´ê³ ì„œ ìƒì„±
      report = analyzer.generate_report(analysis_results)

      # ê²°ê³¼ ì¶œë ¥
      print("\n===== ë¶„ì„ ê²°ê³¼ =====")
      print(f"ì´ ë¦¬ë·° ìˆ˜: {report['summary']['total_reviews']}")

      print("\n===== ìƒìœ„ í‚¤ì›Œë“œ =====")
      for keyword, count in report['summary']['top_keywords']:
        print(f"'{keyword}': {count}íšŒ")

      print("\n===== í‚¤ì›Œë“œë³„ ìƒ˜í”Œ ë¦¬ë·° =====")
      for keyword, data in report['keyword_analysis'].items():
        print(f"\n## '{keyword}' ({data['count']}íšŒ) ##")
        for i, review in enumerate(data['sample_reviews']):
          print(f"{i + 1}. {review[:100]}..." if len(
              review) > 100 else f"{i + 1}. {review}")

      # ê²°ê³¼ë¥¼ ë¡œì»¬ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
      output_directory = "results"

      # ê²°ê³¼ ë””ë ‰í† ë¦¬ê°€ ì—†ìœ¼ë©´ ìƒì„±
      if not os.path.exists(output_directory):
        os.makedirs(output_directory)

      # ë ˆìŠ¤í† ë‘ IDë¡œ íŒŒì¼ëª… ìƒì„±
      result_filename = f"{output_directory}/restaurant_{restaurant_id_str}_keywords.txt"

      try:
        # ê²°ê³¼ë¥¼ ë¡œì»¬ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥
        with open(result_filename, 'w', encoding='utf-8') as f:
          f.write(f"===== ë¶„ì„ ê²°ê³¼ =====\n")
          f.write(f"ë ˆìŠ¤í† ë‘ ID: {restaurant_id_str}\n")
          f.write(f"ì´ ë¦¬ë·° ìˆ˜: {analysis_results['total_reviews']}\n\n")

          f.write(f"===== ìƒìœ„ {top_n}ê°œ í‚¤ì›Œë“œ =====\n")
          for keyword, count in analysis_results['top_keywords']:
            f.write(f"'{keyword}': {count}íšŒ\n")

          f.write("\n===== í‚¤ì›Œë“œë³„ ë¦¬ë·° (ìµœëŒ€ 20ê°œ) =====\n")
          for keyword, data in analysis_results['keyword_reviews'].items():
            f.write(f"\n## '{keyword}' ({data['count']}íšŒ) ##\n")
            for i, review in enumerate(data['reviews'], 1):
              if i > 20:  # ìµœëŒ€ 20ê°œ ë¦¬ë·°ë§Œ í‘œì‹œ
                break
              content = review['content']
              source = review.get('source', 'í”Œë ˆì´ìŠ¤')  # ê¸°ë³¸ê°’ì€ 'í”Œë ˆì´ìŠ¤'ë¡œ ì„¤ì •
              shortened_content = content[:100] + "..." if len(
                  content) > 100 else content
              f.write(f"{i}. [{source}] {shortened_content}\n")

        print(f"âœ… ë¶„ì„ ê²°ê³¼ê°€ í…ìŠ¤íŠ¸ íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {result_filename}")

        # JSON í˜•ì‹ìœ¼ë¡œ í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ ì €ì¥
        # í‚¤ì›Œë“œ ë°°ì—´ í˜•íƒœë¡œ ì €ì¥
        keywords_array = []
        for keyword, count in analysis_results['top_keywords']:
          keyword_obj = {
            'keyword': keyword,
            'count': count,
            'reviews': []
          }

          # ê° í‚¤ì›Œë“œë³„ ë¦¬ë·° ì¶”ê°€ (ìµœëŒ€ 20ê°œ)
          for review in analysis_results['keyword_reviews'].get(keyword,
                                                                {}).get(
              'reviews', [])[:20]:
            content = review.get('content', '')
            source = review.get('source', 'í”Œë ˆì´ìŠ¤')

            review_obj = {
              'content': content,
              'source': source
            }
            keyword_obj['reviews'].append(review_obj)

          keywords_array.append(keyword_obj)

        json_filename = f"{output_directory}/restaurant_{restaurant_id_str}_keywords.json"
        with open(json_filename, 'w', encoding='utf-8') as f:
          json.dump(keywords_array, f, ensure_ascii=False, indent=2)
        print(f"âœ… JSON í˜•ì‹ì˜ í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ê°€ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤: {json_filename}")

        # ë°ì´í„°ë² ì´ìŠ¤ì— ê²°ê³¼ ì €ì¥
        save_keyword_results_to_db(db_importer, restaurant_id_str,
                                   analysis_results)

      except Exception as e:
        print(f"âŒ ê²°ê³¼ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    else:
      print(f"âŒ ë ˆìŠ¤í† ë‘ ID {restaurant_id_str}ì— ëŒ€í•œ ë¶„ì„í•  ìœ íš¨í•œ ë¦¬ë·°ê°€ ì—†ìŠµë‹ˆë‹¤.")

  # ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ì¢…ë£Œ
  db_importer.close()


def save_keyword_results_to_db(db_importer, restaurant_id, analysis_results):
  """
  í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼ë¥¼ ë°ì´í„°ë² ì´ìŠ¤ì— ì €ì¥í•©ë‹ˆë‹¤.

  Args:
      db_importer (PostgresImporter): ë°ì´í„°ë² ì´ìŠ¤ ì—°ê²° ê°ì²´
      restaurant_id (str): ë ˆìŠ¤í† ë‘ ID
      analysis_results (dict): í‚¤ì›Œë“œ ë¶„ì„ ê²°ê³¼
  """
  try:
    print(f"\n===== ë°ì´í„°ë² ì´ìŠ¤ì— í‚¤ì›Œë“œ ë° ë¦¬ë·° ì €ì¥ =====")

    # 1. store_keyword í…Œì´ë¸”ì— í‚¤ì›Œë“œ ì €ì¥
    keyword_id_map = {}  # í‚¤ì›Œë“œì™€ DBì— ì €ì¥ëœ ID ë§¤í•‘ì„ ì €ì¥í•  ì‚¬ì „

    # ìƒìœ„ í‚¤ì›Œë“œ ì²˜ë¦¬
    for idx, (keyword, count) in enumerate(analysis_results['top_keywords'], 1):
      # í‚¤ì›Œë“œ ì €ì¥ ë° ìƒì„±ëœ ID ê°€ì ¸ì˜¤ê¸°
      keyword_id = db_importer._save_keyword(keyword, count, restaurant_id)
      keyword_id_map[keyword] = keyword_id
      print(
          f"âœ… í‚¤ì›Œë“œ '{keyword}' (ë¹ˆë„: {count})ê°€ store_keyword í…Œì´ë¸”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤. ID: {keyword_id}")

    # 2. ê° í‚¤ì›Œë“œë³„ ë¦¬ë·°ë¥¼ keyword_review í…Œì´ë¸”ì— ì €ì¥
    review_count = 0
    for keyword, data in analysis_results['keyword_reviews'].items():
      # í‚¤ì›Œë“œì— í•´ë‹¹í•˜ëŠ” ID ê°€ì ¸ì˜¤ê¸°
      keyword_id = keyword_id_map.get(keyword)
      if not keyword_id:
        print(f"âš ï¸ í‚¤ì›Œë“œ '{keyword}'ì˜ IDë¥¼ ì°¾ì„ ìˆ˜ ì—†ìŠµë‹ˆë‹¤.")
        continue

      # ê° ë¦¬ë·°ë¥¼ ì €ì¥ (ìµœëŒ€ 20ê°œ)
      for review in data['reviews'][:20]:
        content = review.get('content', '')
        # ì†ŒìŠ¤ ì •ë³´ í™•ì¸
        source = review.get('source', 'í”Œë ˆì´ìŠ¤')

        # ë¦¬ë·° ì €ì¥
        relation_id = db_importer._save_review_keyword_relation_with_source(
            content, keyword_id, source)
        if relation_id > 0:
          review_count += 1

    print(f"âœ… ì´ {review_count}ê°œì˜ ë¦¬ë·°ê°€ keyword_review í…Œì´ë¸”ì— ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    return True

  except Exception as e:
    print(f"âŒ ë°ì´í„°ë² ì´ìŠ¤ ì €ì¥ ì¤‘ ì˜¤ë¥˜ ë°œìƒ: {e}")
    return False


if __name__ == "__main__":
  # ì²˜ë¦¬í•  ë ˆìŠ¤í† ë‘ ID ë²”ìœ„ ì„¤ì •
  start_id = 1
  end_id = 1

  # ë ˆìŠ¤í† ë‘ ID ëª©ë¡ (ë²”ìœ„ ë˜ëŠ” íŠ¹ì • ID ëª©ë¡ ì‚¬ìš© ê°€ëŠ¥)
  restaurant_ids = range(start_id, end_id + 1)  # start_idë¶€í„° end_idê¹Œì§€ ì²˜ë¦¬
  # restaurant_ids = [2, 5, 10, 15, 20]  # íŠ¹ì • IDë§Œ ì²˜ë¦¬í•˜ë ¤ë©´ ì´ë ‡ê²Œ ë¦¬ìŠ¤íŠ¸ë¡œ ì§€ì •

  # ì„¤ì •ëœ ë ˆìŠ¤í† ë‘ IDë¡œ ì²˜ë¦¬ ì‹¤í–‰
  main(restaurant_ids)